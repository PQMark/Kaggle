{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "\n",
    "### Use the following code to reload\n",
    "'''\n",
    "import models.model\n",
    "importlib.reload(models.model) \n",
    "'''\n",
    "\n",
    "import wandb\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "from models.MixerMLP import MixerMLP, initialize_weights\n",
    "from models.n_model import DenseNet\n",
    "\n",
    "from customs.focal_loss import FocalLoss\n",
    "\n",
    "from scripts.train import train\n",
    "from scripts.eval import eval\n",
    "from scripts.test import test\n",
    "from scripts.trainer import Trainer\n",
    "from scripts.data_loader import AudioDatasetModule\n",
    "\n",
    "from torchsummaryX import summary\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PHONEME LIST\n",
    "PHONEMES = [\n",
    "            '[SIL]',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',\n",
    "            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n",
    "            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n",
    "            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n",
    "            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n",
    "            'V',     'W',     'Y',     'Z',     'ZH',    '[SOS]', '[EOS]']\n",
    "\n",
    "config = {\n",
    "    'subset': 1.0, # Subset of dataset to use (1.0 == 100% of data)\n",
    "    'context': 24,  # 30\n",
    "    'activations': 'Swish',\n",
    "    'learning_rate': 1e-3,\n",
    "    'dropout': 0.3,\n",
    "    'optimizers': 'AdamW',\n",
    "    'scheduler': 'OneCycleLR',\n",
    "    'epochs': 100,       # 30\n",
    "    'batch_size': 2048, # 1024, 500\n",
    "    'patience': 30,  \n",
    "    'save_every': 1,\n",
    "    'weight_decay': 0.01,\n",
    "    'weight_initialization': 'xavier_normal', # e.g kaiming_normal, kaiming_uniform, uniform, xavier_normal or xavier_uniform\n",
    "    'augmentations': 'FreqMask', # Options: [\"FreqMask\", \"TimeMask\", \"Both\", null]\n",
    "    'freq_mask_param': 4, #4\n",
    "    'time_mask_param': 8\n",
    " }\n",
    "\n",
    "device = \"cuda\"\n",
    "\n",
    "def clean_cache(device):\n",
    "    if device == \"mps\":\n",
    "        torch.mps.empty_cache()\n",
    "    elif device == \"cuda\":\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 1172.27it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 862.40it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1051.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size     :  2048\n",
      "Context        :  24\n",
      "Input size     :  1372\n",
      "Output symbols :  42\n",
      "batches = 19\n",
      "batches = 1\n",
      "batches = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dm = AudioDatasetModule(\n",
    "    root=\"./data\",\n",
    "    phonemes=PHONEMES,\n",
    "    train_partition=\"train-clean-100\",\n",
    "    val_partition=\"dev-clean\",\n",
    "    test_partition=\"test-clean\",\n",
    "    batch_size=config[\"batch_size\"],\n",
    "    config=config,\n",
    "    num_workers=10,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "dm.initialize(mode=\"fit\")\n",
    "train_loader = dm.train_dataloader()\n",
    "val_loader   = dm.val_dataloader()\n",
    "\n",
    "dm.initialize(mode=\"test\")\n",
    "test_loader = dm.test_dataloader()\n",
    "\n",
    "print(\"Batch size     : \", config['batch_size'])\n",
    "print(\"Context        : \", config['context'])\n",
    "print(\"Input size     : \", (2*config['context']+1)*28)\n",
    "print(\"Output symbols : \", len(PHONEMES))\n",
    "\n",
    "print(\"batches = {}\".format(len(train_loader)))\n",
    "print(\"batches = {}\".format(len(val_loader)))\n",
    "print(\"batches = {}\".format(len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_n = DenseNet(arch=(4096, 2048, 1024, 1024, 750, 512), \n",
    "                   num_ouputs=round(len(PHONEMES)), \n",
    "                   dropout=(0.2, 0.15, 0.15, 0.15, 0.05, 0)).to(device)\n",
    "\n",
    "model = model_n\n",
    "model_name = \"model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048, 49, 28])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/amp/grad_scaler.py:132: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "inputs, _ = next(iter(train_loader))\n",
    "model.apply_init(inputs.to(device), initialize_weights)\n",
    "\n",
    "print(inputs.shape)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# criterion = FocalLoss(gamma=1.5)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['learning_rate'], weight_decay=config[\"weight_decay\"])\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=len(train_loader), T_mult=1, \n",
    "#                                                                  eta_min = 0.0001)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=round(len(train_loader) * 1.2), \n",
    "#                                                                  eta_min = 0.00005)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3 * len(train_loader), gamma=0.9)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=2e-3, \n",
    "    total_steps = 20 * len(train_loader), \n",
    "    pct_start = 0.15, \n",
    "    anneal_strategy=\"cos\"\n",
    ")\n",
    "\n",
    "scaler = torch.amp.GradScaler('cuda', enabled=True) \n",
    "\n",
    "clean_cache(device)\n",
    "gc.collect()\n",
    "\n",
    "start=0\n",
    "best_val_acc = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpeng_qiu\u001b[0m (\u001b[33m11785-DL\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/pengqiu/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wandb login \n",
    "wandb.login(key=\"......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 31.0322%\tTrain Loss 2.7459\t Learning Rate 0.0000800\n",
      "\tVal Acc 22.9679%\tVal Loss 3.0323\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:  79%|███████▉  | 15/19 [00:03<00:00,  9.00it/s, acc=64.4206%, loss=1.2610]libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "libc++abi: terminating due to uncaught exception of type std::__1::system_error: Broken pipe\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x17647e020>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1604, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1568, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/connection.py\", line 948, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 38649) is killed by signal: Abort trap: 6. \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# For test\n",
    "wandb.unwatch(model)\n",
    "test_Trainer = Trainer(config[\"epochs\"], criterion, optimizer, scheduler,\n",
    "                       config[\"patience\"], config[\"save_every\"], model_name, device=device, scaler=scaler)\n",
    "test_Trainer.fit(model, train_loader, val_loader, log_epoch=False, log_batch=False, save_best=False,\n",
    "                 checkpoints=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/pengqiu/Desktop/Python/Kaggle/Speech_Recognition/wandb/run-20250214_211431-68l8zlov</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/11785-DL/HW1P2/runs/68l8zlov' target=\"_blank\">test_run_1</a></strong> to <a href='https://wandb.ai/11785-DL/HW1P2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/11785-DL/HW1P2' target=\"_blank\">https://wandb.ai/11785-DL/HW1P2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/11785-DL/HW1P2/runs/68l8zlov' target=\"_blank\">https://wandb.ai/11785-DL/HW1P2/runs/68l8zlov</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create wandb run\n",
    "run = wandb.init(\n",
    "    name    = f\"{model_name}_run_1\", ### set run names\n",
    "    reinit  = True, ### Allows reinitalizing runs when re-running this cell\n",
    "    #id     = \"\", ### Insert specific run id here if resuming a previous run\n",
    "    #resume = \"must\", ### need this to resume previous runs, but comment out reinit = True when using this\n",
    "    project = \"HW1P2\", ### Project name\n",
    "    group=f\"{model_name}\", \n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 31.1641%\tTrain Loss 2.7505\t Learning Rate 0.0000800\n",
      "\tVal Acc 22.4953%\tVal Loss 3.0630\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Acc 65.5057%\tTrain Loss 1.2232\t Learning Rate 0.0005756\n",
      "\tVal Acc 21.9282%\tVal Loss 3.6866\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train:   0%|          | 0/19 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "          File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "     exitcode = _main(fd, parent_sentinel)\n",
      "    ^^^^^^^^^^^  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      " ^  ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^    ^    exitcode = _main(fd, parent_sentinel)^\n",
      "^exitcode = _main(fd, parent_sentinel)\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "                  ^              ^          ^ ^ ^ ^^^^^^\n",
      "^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "      File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "self = reduction.pickle.load(from_parent)\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "           ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/__init__.py\", line 2112, in <module>\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "              self = reduction.pickle.load(from_parent)\n",
      " ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/__init__.py\", line 2183, in <module>\n",
      "^^^^^^^^^^^^^^^^^^Traceback (most recent call last):\n",
      "^^  File \"<string>\", line 1, in <module>\n",
      "^^^  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/__init__.py\", line 2069, in <module>\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "Traceback (most recent call last):\n",
      "^  File \"<string>\", line 1, in <module>\n",
      "^^^  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/__init__.py\", line 2214, in <module>\n",
      "    from torch import _VF as _VF, functional as functional  # usort: skip\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    from torch import quantization as quantization  # usort: skip\n",
      "    from torch import masked as masked\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/masked/__init__.py\", line 1, in <module>\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/quantization/__init__.py\", line 2, in <module>\n",
      "^    ^import torch.nn.functional as F^\n",
      "\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/__init__.py\", line 9, in <module>\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/__init__.py\", line 2069, in <module>\n",
      "    from torch.masked._ops import (\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/masked/_ops.py\", line 10, in <module>\n",
      "    from torch.nn import (\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/attention/__init__.py\", line 7, in <module>\n",
      "    from .fake_quantize import *  # noqa: F403\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/quantization/fake_quantize.py\", line 10, in <module>\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    from torch.masked.maskedtensor.core import is_masked_tensor, MaskedTensor  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/__init__.py\", line 2112, in <module>\n",
      "\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/masked/maskedtensor/__init__.py\", line 4, in <module>\n",
      "    import torch.backends.cuda\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/backends/__init__.py\", line 60, in <module>\n",
      "    from torch.ao.quantization.fake_quantize import (\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/ao/quantization/__init__.py\", line 8, in <module>\n",
      "    from torch import (\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/hub.py\", line 19, in <module>\n",
      "    from torch import _VF as _VF, functional as functional  # usort: skip\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "    from .binary import _apply_native_binary, _is_native_binary\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/masked/maskedtensor/binary.py\", line 178, in <module>\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/__init__.py\", line 9, in <module>\n",
      "    from torch.backends import (\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/backends/mps/__init__.py\", line 6, in <module>\n",
      "    from torch import (    \n",
      "from torch.nn import (\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/parallel/__init__.py\", line 4, in <module>\n",
      "    from torch.library import Library as _Library\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/distributions/__init__.py\", line 74, in <module>\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/library.py\", line 13, in <module>\n",
      "    from .fake_quantize import *  # noqa: F403\n",
      "^    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/ao/quantization/fake_quantize.py\", line 72, in <module>\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/__init__.py\", line 2183, in <module>\n",
      "    from . import transforms    \n",
      "import torch._library as _library    \n",
      "from urllib.request import Request, urlopen\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/_library/__init__.py\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/distributions/transforms.py\", line 12, in <module>\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/urllib/request.py\", line 88, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    NATIVE_BINARY_MAP = {\n",
      "                        ^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/masked/maskedtensor/binary.py\", line 179, in <dictcomp>\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    getattr(torch.ops.aten, name): _torch_binary(name) for name in BINARY_NAMES\n",
      "  ^^      import http.client\n",
      "^^^^^^^^^^^^^^^^^^  File \"/opt/anaconda3/envs/py311/lib/python3.11/http/client.py\", line 71, in <module>\n",
      "^^    ^exitcode = _main(fd, parent_sentinel)^^^^^^^\n",
      "^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/_ops.py\", line 1243, in __getattr__\n",
      "^^\n",
      "               ^^^^^^^^^^    ^from torch.nn.parallel.data_parallel import data_parallel, DataParallel\n",
      "^^^^  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py\", line 17, in <module>\n",
      "^^^^^^^^^^^  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/__init__.py\", line 2548, in <module>\n",
      "\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/spawn.py\", line 132, in _main\n",
      "    from torch.distributions.utils import (\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1138, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1078, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1507, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1479, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1643, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 126, in _path_join\n",
      "KeyboardInterrupt\n",
      "    import torch._library.autograd\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/_library/autograd.py\", line 17, in <module>\n",
      "    opoverloadpacket = OpOverloadPacket(\n",
      "                       ^^^    class FakeQuantizeBase(ABC, Module):\n",
      "  File \"<frozen abc>\", line 107, in __new__\n",
      "KeyboardInterrupt\n",
      "    import email.parser\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/email/parser.py\", line 12, in <module>\n",
      "    from torch.nn.parallel.scatter_gather import gather, scatter_kwargs\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/parallel/scatter_gather.py\", line 6, in <module>\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/__init__.py\", line 2183, in <module>\n",
      "^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/_ops.py\", line 1024, in __init__\n",
      "    @dataclasses.dataclass\n",
      "     ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/dataclasses.py\", line 1232, in dataclass\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/__init__.py\", line 2069, in <module>\n",
      "    from email.feedparser import FeedParser, BytesFeedParser\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/email/feedparser.py\", line 27, in <module>\n",
      "    from torch.nn.parallel._functions import Gather, Scatter\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/parallel/_functions.py\", line 120, in <module>\n",
      "        from torch import quantization as quantization  # usort: skipself._has_torchbind_op_overload = any(\n",
      "\n",
      "                                         ^^^^^^^^^^^^^^^^^^^^^ ^^^^^^^^^\n",
      "^^^^^^^^  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/_ops.py\", line 1025, in <genexpr>\n",
      "^^^^^^^^^^^^\n",
      "    from torch import (\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/quantization/__init__.py\", line 2, in <module>\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/export/__init__.py\", line 28, in <module>\n",
      "    from email._policybase import compat32\n",
      "      File \"/opt/anaconda3/envs/py311/lib/python3.11/email/_policybase.py\", line 7, in <module>\n",
      "from torch import _VF as _VF, functional as functional  # usort: skip\n",
      "    from torch import quantization as quantization  # usort: skip\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^    ^^from .fake_quantize import *  # noqa: F403^^\n",
      "^^^^^^^^^     ^ ^ ^ ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/quantization/fake_quantize.py\", line 10, in <module>\n",
      "^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/quantization/__init__.py\", line 2, in <module>\n",
      "    _has_script_object_arg(schema) for schema in self._schemas.values()\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/_ops.py\", line 1010, in _has_script_object_arg\n",
      "^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/functional.py\", line 7, in <module>\n",
      "    from email import header\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 936, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1032, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1130, in get_data\n",
      "KeyboardInterrupt\n",
      "    return wrap(cls)\n",
      "           ^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/dataclasses.py\", line 1222, in wrap\n",
      "    _streams: Optional[List[Optional[torch.Stream]]] = None\n",
      "      from torch.fx.passes.infra.pass_base import PassResult\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/fx/passes/__init__.py\", line 1, in <module>\n",
      "                     ~~~~^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/typing.py\", line 376, in inner\n",
      "        from torch.ao.quantization.fake_quantize import (\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/ao/quantization/__init__.py\", line 25, in <module>\n",
      "    return _process_class(cls, init, repr, eq, order, unsafe_hash,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^    ^return any(isinstance(arg.type, torch.ClassType) for arg in schema.arguments)^\n",
      "^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/dataclasses.py\", line 1027, in _process_class\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/_ops.py\", line 1010, in <genexpr>\n",
      "from .fake_quantize import *  # noqa: F403\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/quantization/fake_quantize.py\", line 10, in <module>\n",
      "    return cached(*args, **kwds)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/typing.py\", line 1593, in __getitem__\n",
      "    from torch.ao.quantization.fake_quantize import (\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/ao/quantization/__init__.py\", line 28, in <module>\n",
      "    return any(isinstance(arg.type, torch.ClassType) for arg in schema.arguments)\n",
      "\n",
      "KeyboardInterrupt\n",
      "    from . import (\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/fx/passes/graph_drawer.py\", line 13, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/__init__.py\", line 8, in <module>\n",
      "    from .quantization_mappings import *  # noqa: F403 # type: ignore[no-redef]\n",
      "    from .qconfig import *  # noqa: F403\n",
      "    ^^^^^    ^from torch.nn.modules import *  # usort: skip # noqa: F403^\n",
      "^^^^^^^^^^^^  ^ ^ ^^^^^^^ ^^^^^^^^^^^^^^^^^^^^^ ^  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "^^  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/modules/__init__.py\", line 2, in <module>\n",
      "\n",
      "  File \"<frozen importlib._bootstrap>\", line 1138, in _find_and_load_unlocked\n",
      "  File \"<frozen importlib._bootstrap>\", line 1078, in _find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1507, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1479, in _get_spec\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/ao/quantization/quantization_mappings.py\", line 18, in <module>\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1649, in find_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 1604, in _get_spec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 802, in spec_from_file_location\n",
      "KeyboardInterrupt\n",
      "    _init_fn(all_init_fields,\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/dataclasses.py\", line 580, in _init_fn\n",
      "    from torch.fx.passes.shape_prop import TensorMetadata\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/fx/passes/shape_prop.py\", line 8, in <module>\n",
      "    from .linear import Bilinear, Identity, LazyLinear, Linear  # usort: skip\n",
      "    ^^^^^^^^^^^^^^^    return self.copy_with(params)\n",
      "    return _create_fn('__init__',\n",
      "                    ^ ^ ^^^^^^^^^^^    ^import torch.ao.nn.sparse\n",
      "^^^^^^^^  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
      "^^^^  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
      "^^  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\n",
      "^^^KeyboardInterrupt\n",
      "\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "^^^^^^^^^  File \"/opt/anaconda3/envs/py311/lib/python3.11/typing.py\", line 1596, in copy_with\n",
      "^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/modules/linear.py\", line 7, in <module>\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/dataclasses.py\", line 433, in _create_fn\n",
      "    from torch._dispatch.python import enable_python_dispatcher\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/_dispatch/python.py\", line 3, in <module>\n",
      "    exec(txt, globals, ns)\n",
      "  File \"<string>\", line 0, in <module>\n",
      "KeyboardInterrupt\n",
      "    import unittest.mock\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/unittest/__init__.py\", line 66, in <module>\n",
      "    from torch.nn import functional as F, init\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/nn/functional.py\", line 4409, in <module>\n",
      "    return _GenericAlias(self.__origin__, params,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/typing.py\", line 1383, in __init__\n",
      "    from .main import TestProgram, main\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/unittest/main.py\", line 4, in <module>\n",
      "    self.__parameters__ = _collect_parameters(args)\n",
      "    import argparse                          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/typing_extensions.py\", line 3058, in _collect_parameters\n",
      "    @_overload\n",
      "     ^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/_jit_internal.py\", line 1026, in _overload\n",
      "\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/argparse.py\", line 94, in <module>\n",
      "    from gettext import gettext as _, ngettext\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/gettext.py\", line 114, in <module>\n",
      "    _binary_ops = {op: i for i, ops in enumerate(_binary_ops, 1) for op in ops}\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/gettext.py\", line 114, in <dictcomp>\n",
      "    _check_overload_body(func)\n",
      "    _binary_ops = {op: i for i, ops in enumerate(_binary_ops, 1) for op in ops}\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/_jit_internal.py\", line 995, in _check_overload_body\n",
      "    parsed_def = parse_def(func)\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/_sources.py\", line 127, in parse_def\n",
      "    elif hasattr(t, '__typing_subst__'):\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "    py_ast = ast.parse(dedent_src)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/ast.py\", line 50, in parse\n",
      "    return compile(source, filename, mode, flags,\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x1055f7f10>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "  File \"/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 38798) is killed by signal: Interrupt: 2. \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 9\u001b[0m\n\u001b[1;32m      3\u001b[0m wandb\u001b[38;5;241m.\u001b[39mwatch(model, log\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m], criterion, optimizer, scheduler, \n\u001b[1;32m      6\u001b[0m                        config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatience\u001b[39m\u001b[38;5;124m\"\u001b[39m], config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msave_every\u001b[39m\u001b[38;5;124m\"\u001b[39m], model_name, \n\u001b[1;32m      7\u001b[0m                        start\u001b[38;5;241m=\u001b[39mstart, best_val_acc\u001b[38;5;241m=\u001b[39mbest_val_acc, \n\u001b[1;32m      8\u001b[0m                        device\u001b[38;5;241m=\u001b[39mdevice, scaler\u001b[38;5;241m=\u001b[39mscaler)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_best\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoints\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Python/Kaggle/Speech_Recognition/scripts/trainer.py:32\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_loader, val_loader, early_stopping, log_epoch, log_batch, log_freq, save_best, checkpoints)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_epochs))\n\u001b[1;32m     31\u001b[0m curr_lr                 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m---> 32\u001b[0m train_loss, train_acc   \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m val_loss, val_acc       \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(model, val_loader, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTrain Acc \u001b[39m\u001b[38;5;132;01m{:.04f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTrain Loss \u001b[39m\u001b[38;5;132;01m{:.04f}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m Learning Rate \u001b[39m\u001b[38;5;132;01m{:.07f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(train_acc\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m, train_loss, curr_lr))\n",
      "File \u001b[0;32m~/Desktop/Python/Kaggle/Speech_Recognition/scripts/train.py:15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, scheduler, optimizer, criterion, device, log_batch, log_freq, scaler, max_grad_norm)\u001b[0m\n\u001b[1;32m     11\u001b[0m tloss, tacc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m \n\u001b[1;32m     13\u001b[0m batch_bar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(dataloader), dynamic_ncols\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mframes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphonemes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# if i == len(dataloader) // 3:\u001b[39;49;00m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#     torch.save(model.state_dict(), f'checkpoints/model_d/intermediate_batch{i+1}_model.pth')\u001b[39;49;00m\n\u001b[1;32m     19\u001b[0m \n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Initialize Gradients\u001b[39;49;00m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mframes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1448\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1447\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1448\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1450\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1451\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1412\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1408\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1409\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1411\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1412\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1413\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1414\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1243\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1241\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1243\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1245\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1246\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1247\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[1;32m    112\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll():\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/multiprocessing/connection.py:948\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    945\u001b[0m     deadline \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 948\u001b[0m     ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    949\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ready:\n\u001b[1;32m    950\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [key\u001b[38;5;241m.\u001b[39mfileobj \u001b[38;5;28;01mfor\u001b[39;00m (key, events) \u001b[38;5;129;01min\u001b[39;00m ready]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selector\u001b[38;5;241m.\u001b[39mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x36c8bb110>> (for post_run_cell), with arguments args (<ExecutionResult object at 36c8b19d0, execution_count=8 error_before_exec=None error_in_exec= info=<ExecutionInfo object at 157287710, raw_cell=\"clean_cache(device)\n",
      "gc.collect()\n",
      "wandb.watch(model..\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/Users/pengqiu/Desktop/Python/Kaggle/Speech_Recognition/main.ipynb#X62sZmlsZQ%3D%3D> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/site-packages/wandb/sdk/wandb_init.py:542\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/site-packages/wandb/sdk/interface/interface.py:771\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    770\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[0;32m--> 771\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/site-packages/wandb/sdk/interface/interface_shared.py:368\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[0;34m(self, pause)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    367\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[0;32m--> 368\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/site-packages/wandb/sdk/interface/interface_sock.py:47\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[0;34m(self, record, local)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:222\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[0;34m(self, record)\u001b[0m\n\u001b[1;32m    220\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[1;32m    221\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:154\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:151\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/py311/lib/python3.11/site-packages/wandb/sdk/lib/sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "clean_cache(device)\n",
    "gc.collect()\n",
    "wandb.watch(model, log=\"all\")\n",
    "\n",
    "trainer = Trainer(config[\"epochs\"], criterion, optimizer, scheduler, \n",
    "                       config[\"patience\"], config[\"save_every\"], model_name, \n",
    "                       start=start, best_val_acc=best_val_acc, \n",
    "                       device=device, scaler=scaler)\n",
    "trainer.fit(model, train_loader, val_loader, save_best=True, checkpoints=True, log_freq=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"----------------------------------------------------------------------\"\n",
    "\"----------------------------Resume Run--------------------------------\"\n",
    "\"----------------------------------------------------------------------\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "checkpoint = torch.load(\"checkpoints/model/model_epoch_40.pth\")\n",
    "\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "# optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "# scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "\n",
    "start=40\n",
    "best_val_acc = 0.86"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "    name    = f\"{model_name}_run_1\",\n",
    "    reinit  = True,\n",
    "    id      = '......',   ### ID for the run\n",
    "    resume  = \"must\", \n",
    "    project = \"HW1P2\",\n",
    "    group=f\"{model_name}\",\n",
    "    config=config\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
